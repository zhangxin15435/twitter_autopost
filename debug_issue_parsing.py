#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•Issueå†…å®¹è§£æé—®é¢˜
æµ‹è¯•ä¸åŒæ ¼å¼çš„å†…å®¹è§£æç»“æœ
"""

import re
import json

def parse_issue_content(content):
    """è§£æIssueå†…å®¹ï¼Œæå–æ¨æ–‡æ•°æ®ï¼ˆä¸å·¥ä½œæµä¸­ç›¸åŒçš„é€»è¾‘ï¼‰"""
    tweets = []
    
    print(f"ğŸ” åŸå§‹å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
    print(f"ğŸ“ åŸå§‹å†…å®¹:\n{repr(content)}")
    print("=" * 60)
    
    # æ–¹æ³•1ï¼šJSONæ ¼å¼
    json_match = re.search(r'```json\n(.*?)\n```', content, re.DOTALL)
    if json_match:
        try:
            data = json.loads(json_match.group(1))
            if isinstance(data, list):
                tweets.extend(data)
            else:
                tweets.append(data)
            print("âœ… æ‰¾åˆ°JSONæ ¼å¼å†…å®¹")
            return tweets
        except:
            print("âŒ JSONæ ¼å¼è§£æå¤±è´¥")
            pass
    
    # æ–¹æ³•2ï¼šç»“æ„åŒ–æ–‡æœ¬æ ¼å¼
    lines = content.split('\n')
    current_tweet = {}
    
    print(f"ğŸ“„ æ€»è¡Œæ•°: {len(lines)}")
    
    for i, line in enumerate(lines):
        line = line.strip()
        print(f"ç¬¬{i+1}è¡Œ: {repr(line)}")
        
        if line.startswith('**å†…å®¹:**') or line.startswith('å†…å®¹:'):
            content_text = line.split(':', 1)[1].strip()
            # æ¸…ç†å¯èƒ½çš„æ˜Ÿå·
            content_text = content_text.lstrip('*').strip()
            current_tweet['content'] = content_text
            print(f"  â†’ æ‰¾åˆ°å†…å®¹: {repr(content_text)}")
        elif line.startswith('**è´¦å·:**') or line.startswith('è´¦å·:'):
            account_text = line.split(':', 1)[1].strip()
            # æ¸…ç†å¯èƒ½çš„æ˜Ÿå·
            account_text = account_text.lstrip('*').strip()
            current_tweet['account'] = account_text
            print(f"  â†’ æ‰¾åˆ°è´¦å·: {repr(account_text)}")
        elif line.startswith('---') and current_tweet:
            tweets.append(current_tweet)
            print(f"  â†’ æ·»åŠ æ¨æ–‡: {current_tweet}")
            current_tweet = {}
    
    # æ·»åŠ æœ€åä¸€æ¡æ¨æ–‡
    if current_tweet.get('content'):
        tweets.append(current_tweet)
        print(f"â†’ æ·»åŠ æœ€åæ¨æ–‡: {current_tweet}")
    
    # æ–¹æ³•3ï¼šç®€å•æ ¼å¼ï¼ˆå¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»“æ„åŒ–å†…å®¹ï¼‰
    if not tweets:
        print("ğŸ”„ å°è¯•ç®€å•æ ¼å¼è§£æ...")
        
        # æŸ¥æ‰¾å¯èƒ½çš„æ¨æ–‡å†…å®¹
        content_lines = [line.strip() for line in lines if line.strip() and not line.startswith('#')]
        
        print(f"ğŸ“‹ è¿‡æ»¤åçš„å†…å®¹è¡Œæ•°: {len(content_lines)}")
        for i, line in enumerate(content_lines):
            print(f"  å†…å®¹è¡Œ{i+1}: {repr(line)}")
        
        if content_lines:
            # å–æ‰€æœ‰å†…å®¹ï¼Œä½†æ£€æŸ¥é•¿åº¦é™åˆ¶
            full_content = '\n'.join(content_lines)
            print(f"ğŸ“ åˆå¹¶åçš„å®Œæ•´å†…å®¹é•¿åº¦: {len(full_content)}")
            print(f"ğŸ“ åˆå¹¶åçš„å®Œæ•´å†…å®¹: {repr(full_content)}")
            
            # å¦‚æœå†…å®¹è¶…è¿‡280å­—ç¬¦ï¼Œæˆªæ–­å¹¶æ·»åŠ æç¤º
            if len(full_content) > 280:
                truncated_content = full_content[:270] + "...[å†…å®¹è¿‡é•¿å·²æˆªæ–­]"
                print(f"âš ï¸ å†…å®¹è¶…é•¿({len(full_content)}å­—ç¬¦)ï¼Œå·²æˆªæ–­ä¸º: {truncated_content}")
                tweets.append({
                    'content': truncated_content,
                    'account': 'ContextSpace'  # é»˜è®¤è´¦å·
                })
            else:
                tweets.append({
                    'content': full_content,
                    'account': 'ContextSpace'  # é»˜è®¤è´¦å·
                })
    
    print("=" * 60)
    print(f"ğŸ¯ æœ€ç»ˆè§£æç»“æœ: {len(tweets)} æ¡æ¨æ–‡")
    for i, tweet in enumerate(tweets):
        print(f"  æ¨æ–‡{i+1}: å†…å®¹é•¿åº¦={len(tweet.get('content', ''))} å­—ç¬¦")
        print(f"         è´¦å·={tweet.get('account', 'N/A')}")
        print(f"         å†…å®¹å‰50å­—ç¬¦: {repr(tweet.get('content', '')[:50])}")
    
    return tweets

def test_multi_line_content():
    """æµ‹è¯•å¤šè¡Œå†…å®¹è§£æ"""
    print("ğŸ§ª æµ‹è¯•1: å¤šè¡Œåˆ—è¡¨å†…å®¹")
    print("=" * 80)
    
    test_content = """å¸¸è§çš„æä¾›å…è´¹ä»£ç†çš„ç½‘ç«™ï¼š
https://www.freeproxylists.net
https://www.hidemyass.com
https://www.proxyscrape.com
http://spys.one
https://www.sslproxies.org
https://www.kproxy.com
https://whoer.net"""
    
    result = parse_issue_content(test_content)
    
    print("\nğŸ§ª æµ‹è¯•2: å¸¦ç»“æ„åŒ–æ ¼å¼çš„å†…å®¹")
    print("=" * 80)
    
    test_content2 = """**å†…å®¹:** å¸¸è§çš„æä¾›å…è´¹ä»£ç†çš„ç½‘ç«™ï¼š
https://www.freeproxylists.net
https://www.hidemyass.com
https://www.proxyscrape.com
**è´¦å·:** ContextSpace"""
    
    result2 = parse_issue_content(test_content2)

def test_actual_issue_content():
    """æµ‹è¯•å®é™…Issueå†…å®¹"""
    print("ğŸ§ª æµ‹è¯•3: æ¨¡æ‹Ÿå®é™…Issueå†…å®¹")
    print("=" * 80)
    
    # æ¨¡æ‹ŸGitHub Issueçš„å®é™…å†…å®¹æ ¼å¼
    test_content3 = """## ğŸ“ æ¨æ–‡å†…å®¹

å¸¸è§çš„æä¾›å…è´¹ä»£ç†çš„ç½‘ç«™ï¼š
https://www.freeproxylists.net
https://www.hidemyass.com
https://www.proxyscrape.com
http://spys.one
https://www.sslproxies.org
https://www.kproxy.com
https://whoer.net

## å…¶ä»–ä¿¡æ¯

å‘å¸ƒæ—¶é—´: 2024-01-01"""
    
    result3 = parse_issue_content(test_content3)

if __name__ == "__main__":
    print("ğŸ” Issueå†…å®¹è§£æè°ƒè¯•å™¨")
    print("=" * 80)
    
    test_multi_line_content()
    test_actual_issue_content()
    
    print("\nâœ… è°ƒè¯•å®Œæˆ") 