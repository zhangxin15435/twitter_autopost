#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Twitterè‡ªåŠ¨å‘å¸ƒç³»ç»Ÿ - Contentæ–‡ä»¶å¤¹ç‰ˆæœ¬
ä»contentæ–‡ä»¶å¤¹ä¸­çš„è¡¨æ ¼æ–‡ä»¶è¯»å–å†…å®¹å¹¶å‘å¸ƒåˆ°Twitter
"""

import os
import csv
import time
import logging
from datetime import datetime
from typing import Dict, List, Optional
from connect_twitter import TwitterAPI

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('twitter_auto.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ContentFolderTwitterPublisher:
    """Contentæ–‡ä»¶å¤¹Twitterå‘å¸ƒå™¨"""
    
    def __init__(self, content_folder: str = "content"):
        """åˆå§‹åŒ–å‘å¸ƒå™¨"""
        self.content_folder = content_folder
        self.twitter_api = None
        self.current_data = []
        
        # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        self.supported_formats = ['.csv']
        
        logger.info(f"Contentæ–‡ä»¶å¤¹Twitterå‘å¸ƒå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def connect_twitter(self) -> bool:
        """è¿æ¥Twitter API"""
        try:
            self.twitter_api = TwitterAPI()
            
            # æµ‹è¯•è¿æ¥
            if self.twitter_api.test_connection():
                logger.info(f"âœ… Twitter APIè¿æ¥æˆåŠŸ")
                return True
            else:
                logger.error("âŒ Twitter APIè¿æ¥å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Twitter APIè¿æ¥é”™è¯¯: {str(e)}")
            return False
    
    def load_content_data(self) -> List[Dict]:
        """åŠ è½½contentæ–‡ä»¶å¤¹ä¸­çš„æ•°æ®"""
        try:
            # æŸ¥æ‰¾CSVæ–‡ä»¶
            csv_files = []
            for file in os.listdir(self.content_folder):
                if file.endswith('.csv'):
                    csv_files.append(os.path.join(self.content_folder, file))
            
            if not csv_files:
                logger.warning("åœ¨contentæ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°CSVæ–‡ä»¶")
                return []
            
            logger.info(f"æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
            
            all_data = []
            for csv_file in csv_files:
                logger.info(f"è¯»å–æ–‡ä»¶: {os.path.basename(csv_file)}")
                
                try:
                    # å°è¯•ä¸åŒç¼–ç 
                    encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312']
                    data = None
                    
                    for encoding in encodings:
                        try:
                            with open(csv_file, 'r', encoding=encoding) as f:
                                reader = csv.DictReader(f)
                                data = list(reader)
                                logger.info(f"æˆåŠŸä½¿ç”¨ç¼–ç  {encoding} è¯»å– {len(data)} è¡Œæ•°æ®")
                                break
                        except Exception:
                            continue
                    
                    if not data:
                        logger.error(f"æ— æ³•è¯»å–æ–‡ä»¶ {csv_file}")
                        continue
                    
                    # å¤„ç†æ•°æ®
                    processed_data = self.process_csv_data(data, csv_file)
                    all_data.extend(processed_data)
                    
                except Exception as e:
                    logger.error(f"å¤„ç†æ–‡ä»¶ {csv_file} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            
            self.current_data = all_data
            logger.info(f"æ€»å…±åŠ è½½ {len(all_data)} æ¡æœ‰æ•ˆæ•°æ®")
            return all_data
            
        except Exception as e:
            logger.error(f"åŠ è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return []
    
    def process_csv_data(self, raw_data: List[Dict], file_path: str) -> List[Dict]:
        """å¤„ç†CSVæ•°æ®"""
        processed_data = []
        
        for i, row in enumerate(raw_data):
            try:
                # è·å–å†…å®¹ä¸»é¢˜ï¼ˆå¯èƒ½åŒ…å«å¼•å·ï¼‰
                content = ""
                for field_name in row.keys():
                    if 'å†…å®¹ä¸»é¢˜' in field_name:  # åŒ¹é…åŒ…å«"å†…å®¹ä¸»é¢˜"çš„å­—æ®µ
                        content = row[field_name]
                        break
                
                if not content or not content.strip():
                    continue
                
                # è·å–å…¶ä»–å­—æ®µ
                author = row.get('æå‡ºäºº', '').strip()
                source = row.get('å‘å¸ƒè´¦å·', '').strip()
                publish_status = row.get('æ˜¯å¦å‘å¸ƒ', '').strip()
                
                # åˆ›å»ºæ ‡å‡†æ ¼å¼çš„æ•°æ®
                processed_row = {
                    'title': content[:50] + "..." if len(content) > 50 else content,
                    'content': content.strip(),
                    'author': author,
                    'source': source,
                    'published': publish_status,
                    'is_published': publish_status.lower() in ['æ˜¯', 'yes', 'true', '1'],
                    '_source_file': file_path,
                    '_row_index': i,
                    '_original_row': row
                }
                
                processed_data.append(processed_row)
                
            except Exception as e:
                logger.error(f"å¤„ç†ç¬¬ {i+1} è¡Œæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        
        logger.info(f"ä» {os.path.basename(file_path)} å¤„ç†äº† {len(processed_data)} æ¡æœ‰æ•ˆæ•°æ®")
        return processed_data
    
    def get_next_article(self) -> Optional[Dict]:
        """è·å–ä¸‹ä¸€ç¯‡å¾…å‘å¸ƒçš„æ–‡ç« """
        if not self.current_data:
            self.load_content_data()
        
        # æŸ¥æ‰¾æœªå‘å¸ƒçš„æ–‡ç« 
        for article in self.current_data:
            if not article['is_published']:
                return article
        
        return None
    
    def format_tweet_content(self, article: Dict) -> str:
        """æ ¼å¼åŒ–æ¨æ–‡å†…å®¹"""
        content = article['content']
        
        # å¦‚æœå†…å®¹è¶…è¿‡Twitterå­—ç¬¦é™åˆ¶ï¼Œè¿›è¡Œæˆªæ–­
        max_length = 280
        if len(content) > max_length:
            content = content[:max_length-3] + "..."
        
        return content
    
    def publish_article(self, article: Dict) -> bool:
        """å‘å¸ƒæ–‡ç« åˆ°Twitter"""
        try:
            if not self.twitter_api:
                logger.error("Twitter APIæœªè¿æ¥")
                return False
            
            # æ ¼å¼åŒ–æ¨æ–‡å†…å®¹
            tweet_content = self.format_tweet_content(article)
            
            logger.info(f"å‡†å¤‡å‘å¸ƒæ¨æ–‡: {tweet_content[:100]}...")
            
            # å‘å¸ƒæ¨æ–‡
            result = self.twitter_api.create_tweet(tweet_content)
            
            if result and result.get('id'):
                tweet_id = result.get('id')
                logger.info(f"ğŸ‰ æ¨æ–‡å‘å¸ƒæˆåŠŸï¼æ¨æ–‡ID: {tweet_id}")
                
                # æ ‡è®°ä¸ºå·²å‘å¸ƒ
                if self.mark_as_published(article):
                    logger.info("âœ… æ–‡ç« çŠ¶æ€æ›´æ–°æˆåŠŸ")
                else:
                    logger.warning("âš ï¸ æ–‡ç« çŠ¶æ€æ›´æ–°å¤±è´¥")
                
                return True
            else:
                logger.error(f"âŒ æ¨æ–‡å‘å¸ƒå¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"å‘å¸ƒæ–‡ç« æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False
    
    def mark_as_published(self, article: Dict) -> bool:
        """æ ‡è®°æ–‡ç« ä¸ºå·²å‘å¸ƒ"""
        try:
            source_file = article['_source_file']
            row_index = article['_row_index']
            
            # è¯»å–åŸå§‹æ–‡ä»¶
            with open(source_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                rows = list(reader)
                fieldnames = reader.fieldnames
            
            # æ‰¾åˆ°å‘å¸ƒçŠ¶æ€å­—æ®µ
            status_field = None
            for field in fieldnames:
                if 'æ˜¯å¦å‘å¸ƒ' in field:
                    status_field = field
                    break
            
            if not status_field:
                logger.error("æœªæ‰¾åˆ°å‘å¸ƒçŠ¶æ€å­—æ®µ")
                return False
            
            # æ›´æ–°çŠ¶æ€
            if row_index < len(rows):
                rows[row_index][status_field] = 'æ˜¯'
                
                # å†™å›æ–‡ä»¶
                with open(source_file, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(rows)
                
                # æ›´æ–°å†…å­˜ä¸­çš„æ•°æ®
                article['is_published'] = True
                article['published'] = 'æ˜¯'
                
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"æ ‡è®°å·²å‘å¸ƒæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.current_data:
            self.load_content_data()
        
        total = len(self.current_data)
        published = sum(1 for article in self.current_data if article['is_published'])
        unpublished = total - published
        
        return {
            'total': total,
            'published': published,
            'unpublished': unpublished
        }
    
    def run_once(self) -> bool:
        """è¿è¡Œä¸€æ¬¡å‘å¸ƒä»»åŠ¡"""
        try:
            logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œå‘å¸ƒä»»åŠ¡")
            
            # è¿æ¥Twitter
            if not self.connect_twitter():
                return False
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = self.get_statistics()
            logger.info(f"ğŸ“Š å†…å®¹ç»Ÿè®¡: æ€»æ•°={stats['total']}, å·²å‘å¸ƒ={stats['published']}, æœªå‘å¸ƒ={stats['unpublished']}")
            
            # è·å–ä¸‹ä¸€ç¯‡æ–‡ç« 
            article = self.get_next_article()
            
            if not article:
                logger.info("âœ… æ²¡æœ‰å¾…å‘å¸ƒçš„æ–‡ç« ")
                return True
            
            logger.info(f"ğŸ“ å‡†å¤‡å‘å¸ƒ: {article['title']}")
            logger.info(f"ğŸ‘¤ ä½œè€…: {article['author']}")
            logger.info(f"ğŸ“ æ¥æº: {article['source']}")
            
            # å‘å¸ƒæ–‡ç« 
            success = self.publish_article(article)
            
            if success:
                logger.info("ğŸ‰ å‘å¸ƒä»»åŠ¡å®Œæˆ")
            else:
                logger.error("âŒ å‘å¸ƒä»»åŠ¡å¤±è´¥")
            
            return success
            
        except Exception as e:
            logger.error(f"è¿è¡Œå‘å¸ƒä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Twitterè‡ªåŠ¨å‘å¸ƒç³»ç»Ÿ - Contentæ–‡ä»¶å¤¹ç‰ˆæœ¬")
    print("=" * 50)
    
    try:
        # åˆ›å»ºå‘å¸ƒå™¨
        publisher = ContentFolderTwitterPublisher()
        
        # è¿è¡Œä¸€æ¬¡
        success = publisher.run_once()
        
        if success:
            print("âœ… å‘å¸ƒä»»åŠ¡å®Œæˆ")
        else:
            print("âŒ å‘å¸ƒä»»åŠ¡å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main() 