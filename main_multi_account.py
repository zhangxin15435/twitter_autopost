#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Twitterå¤šè´¦å·è‡ªåŠ¨å‘å¸ƒç³»ç»Ÿ
ä»contentæ–‡ä»¶å¤¹ä¸­çš„è¡¨æ ¼æ–‡ä»¶è¯»å–å†…å®¹ï¼Œå¹¶æ ¹æ®"å‘å¸ƒè´¦å·"å­—æ®µé€‰æ‹©å¯¹åº”çš„Twitterè´¦å·å‘å¸ƒ
"""

import os
import csv
import time
import logging
from datetime import datetime
from typing import Dict, List, Optional
from connect_twitter_multi import TwitterAccountManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('twitter_multi_auto.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MultiAccountTwitterPublisher:
    """å¤šè´¦å·Twitterå‘å¸ƒå™¨"""
    
    def __init__(self, content_folder: str = "content", excluded_accounts: List[str] = None):
        """
        åˆå§‹åŒ–å‘å¸ƒå™¨
        
        Args:
            content_folder: å†…å®¹æ–‡ä»¶å¤¹è·¯å¾„
            excluded_accounts: æš‚æ—¶æ’é™¤çš„è´¦å·åˆ—è¡¨
        """
        self.content_folder = content_folder
        self.account_manager = TwitterAccountManager()
        self.current_data = []
        
        # æš‚æ—¶æ’é™¤çš„è´¦å·åˆ—è¡¨
        self.excluded_accounts = excluded_accounts or []
        
        # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        self.supported_formats = ['.csv']
        
        if self.excluded_accounts:
            logger.info(f"å¤šè´¦å·Twitterå‘å¸ƒå™¨åˆå§‹åŒ–å®Œæˆ (æ’é™¤è´¦å·: {', '.join(self.excluded_accounts)})")
        else:
            logger.info(f"å¤šè´¦å·Twitterå‘å¸ƒå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def publish_single_tweet(self, content: str, account_name: str) -> bool:
        """
        å‘å¸ƒå•æ¡æ¨æ–‡åˆ°æŒ‡å®šè´¦å·
        
        Args:
            content: æ¨æ–‡å†…å®¹
            account_name: è´¦å·åç§°ï¼ˆå¦‚ 'ContextSpace', 'OSS Discoveries' ç­‰ï¼‰
            
        Returns:
            bool: å‘å¸ƒæ˜¯å¦æˆåŠŸ
        """
        try:
            # æ ‡å‡†åŒ–è´¦å·åç§°
            account_mapping = {
                'contextspace': 'contextspace',
                'context space': 'contextspace', 
                'twitter': 'contextspace',
                'oss discoveries': 'ossdiscoveries',
                'ossdiscoveries': 'ossdiscoveries',
                'oss': 'ossdiscoveries',
                'ai flow watch': 'aiflowwatch',
                'aiflowwatch': 'aiflowwatch', 
                'ai': 'aiflowwatch',
                'open source reader': 'opensourcereader',
                'opensourcereader': 'opensourcereader',
                'reader': 'opensourcereader'
            }
            
            normalized_account = account_mapping.get(account_name.lower().strip(), 'contextspace')
            
            # æ£€æŸ¥è´¦å·æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
            if normalized_account in self.excluded_accounts:
                logger.warning(f"è´¦å· {normalized_account} å·²è¢«æ’é™¤ï¼Œè·³è¿‡å‘å¸ƒ")
                return False
            
            # è·å–APIè¿æ¥
            api = self.account_manager.get_api(normalized_account)
            if not api:
                logger.error(f"æ— æ³•è·å–è´¦å· {normalized_account} çš„APIè¿æ¥")
                return False
            
            # å‘å¸ƒæ¨æ–‡
            logger.info(f"æ­£åœ¨å‘å¸ƒæ¨æ–‡åˆ°è´¦å· {normalized_account}")
            logger.info(f"æ¨æ–‡å†…å®¹: {content[:50]}...")
            
            response = api.create_tweet(text=content)
            
            if response and response.data:
                tweet_id = response.data['id']
                logger.info(f"âœ… æ¨æ–‡å‘å¸ƒæˆåŠŸï¼Tweet ID: {tweet_id}")
                return True
            else:
                logger.error(f"âŒ æ¨æ–‡å‘å¸ƒå¤±è´¥ï¼ŒAPIå“åº”å¼‚å¸¸")
                return False
                
        except Exception as e:
            logger.error(f"ğŸ’¥ å‘å¸ƒæ¨æ–‡æ—¶å‡ºç°å¼‚å¸¸: {str(e)}")
            return False
    
    def load_content_data(self) -> List[Dict]:
        """åŠ è½½contentæ–‡ä»¶å¤¹ä¸­çš„æ•°æ®"""
        try:
            # æŸ¥æ‰¾CSVæ–‡ä»¶
            csv_files = []
            for file in os.listdir(self.content_folder):
                if file.endswith('.csv'):
                    csv_files.append(os.path.join(self.content_folder, file))
            
            if not csv_files:
                logger.warning("åœ¨contentæ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°CSVæ–‡ä»¶")
                return []
            
            logger.info(f"æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
            
            all_data = []
            for csv_file in csv_files:
                logger.info(f"è¯»å–æ–‡ä»¶: {os.path.basename(csv_file)}")
                
                try:
                    # å°è¯•ä¸åŒç¼–ç 
                    encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312']
                    data = None
                    
                    for encoding in encodings:
                        try:
                            with open(csv_file, 'r', encoding=encoding) as f:
                                reader = csv.DictReader(f)
                                data = list(reader)
                                logger.info(f"æˆåŠŸä½¿ç”¨ç¼–ç  {encoding} è¯»å– {len(data)} è¡Œæ•°æ®")
                                break
                        except Exception:
                            continue
                    
                    if not data:
                        logger.error(f"æ— æ³•è¯»å–æ–‡ä»¶ {csv_file}")
                        continue
                    
                    # å¤„ç†æ•°æ®
                    processed_data = self.process_csv_data(data, csv_file)
                    all_data.extend(processed_data)
                    
                except Exception as e:
                    logger.error(f"å¤„ç†æ–‡ä»¶ {csv_file} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            
            self.current_data = all_data
            logger.info(f"æ€»å…±åŠ è½½ {len(all_data)} æ¡æœ‰æ•ˆæ•°æ®")
            return all_data
            
        except Exception as e:
            logger.error(f"åŠ è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return []
    
    def process_csv_data(self, raw_data: List[Dict], file_path: str) -> List[Dict]:
        """å¤„ç†CSVæ•°æ®"""
        processed_data = []
        
        for i, row in enumerate(raw_data):
            try:
                # è·å–å†…å®¹ä¸»é¢˜ï¼ˆå¯èƒ½åŒ…å«å¼•å·ï¼‰
                content = ""
                for field_name in row.keys():
                    if 'å†…å®¹ä¸»é¢˜' in field_name:  # åŒ¹é…åŒ…å«"å†…å®¹ä¸»é¢˜"çš„å­—æ®µ
                        content = row[field_name]
                        break
                
                if not content or not content.strip():
                    continue
                
                # è·å–å…¶ä»–å­—æ®µ
                author = row.get('æå‡ºäºº', '').strip()
                source = row.get('å‘å¸ƒè´¦å·', '').strip()
                publish_status = row.get('æ˜¯å¦å‘å¸ƒ', '').strip()
                
                # åˆ›å»ºæ ‡å‡†æ ¼å¼çš„æ•°æ®
                processed_row = {
                    'title': content[:50] + "..." if len(content) > 50 else content,
                    'content': content.strip(),
                    'author': author,
                    'source': source,
                    'publish_account': source,  # å‘å¸ƒè´¦å·
                    'published': publish_status,
                    'is_published': publish_status.lower() in ['æ˜¯', 'yes', 'true', '1'],
                    '_source_file': file_path,
                    '_row_index': i,
                    '_original_row': row
                }
                
                processed_data.append(processed_row)
                
            except Exception as e:
                logger.error(f"å¤„ç†ç¬¬ {i+1} è¡Œæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        
        logger.info(f"ä» {os.path.basename(file_path)} å¤„ç†äº† {len(processed_data)} æ¡æœ‰æ•ˆæ•°æ®")
        return processed_data
    
    def get_next_articles_by_account(self) -> Dict[str, List[Dict]]:
        """æŒ‰è´¦å·åˆ†ç»„è·å–å¾…å‘å¸ƒçš„æ–‡ç« """
        if not self.current_data:
            self.load_content_data()
        
        # æŒ‰è´¦å·åˆ†ç»„
        articles_by_account = {}
        
        for article in self.current_data:
            if not article['is_published']:
                account = article['publish_account']
                if not account:
                    account = 'default'  # é»˜è®¤è´¦å·
                
                # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
                if account in self.excluded_accounts:
                    logger.info(f"è·³è¿‡æ’é™¤è´¦å·: {account}")
                    continue
                
                if account not in articles_by_account:
                    articles_by_account[account] = []
                
                articles_by_account[account].append(article)
        
        return articles_by_account
    
    def get_next_article(self) -> Optional[Dict]:
        """è·å–ä¸‹ä¸€ç¯‡å¾…å‘å¸ƒçš„æ–‡ç« """
        if not self.current_data:
            self.load_content_data()
        
        # æŸ¥æ‰¾æœªå‘å¸ƒçš„æ–‡ç« 
        for article in self.current_data:
            if not article['is_published']:
                account = article['publish_account']
                if not account:
                    account = 'default'
                
                # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
                if account in self.excluded_accounts:
                    logger.info(f"è·³è¿‡æ’é™¤è´¦å·: {account}")
                    continue
                
                return article
        
        return None
    
    def format_tweet_content(self, article: Dict) -> str:
        """æ ¼å¼åŒ–æ¨æ–‡å†…å®¹"""
        content = article['content']
        
        # å¦‚æœå†…å®¹è¶…è¿‡Twitterå­—ç¬¦é™åˆ¶ï¼Œè¿›è¡Œæˆªæ–­
        max_length = 280
        if len(content) > max_length:
            content = content[:max_length-3] + "..."
        
        return content
    
    def publish_article(self, article: Dict) -> bool:
        """å‘å¸ƒæ–‡ç« åˆ°å¯¹åº”çš„Twitterè´¦å·"""
        try:
            # è·å–å‘å¸ƒè´¦å·
            publish_account = article['publish_account']
            if not publish_account:
                publish_account = 'default'
            
            logger.info(f"å‡†å¤‡å‘å¸ƒåˆ°è´¦å·: {publish_account}")
            
            # æ ¼å¼åŒ–æ¨æ–‡å†…å®¹
            tweet_content = self.format_tweet_content(article)
            
            logger.info(f"å‡†å¤‡å‘å¸ƒæ¨æ–‡: {tweet_content[:100]}...")
            
            # å‘å¸ƒæ¨æ–‡
            result = self.account_manager.publish_tweet(publish_account, tweet_content)
            
            if result and result.get('id'):
                tweet_id = result.get('id')
                username = result.get('username', 'unknown')
                tweet_url = result.get('url', '')
                
                logger.info(f"ğŸ‰ æ¨æ–‡å‘å¸ƒæˆåŠŸï¼")
                logger.info(f"   è´¦å·: @{username}")
                logger.info(f"   æ¨æ–‡ID: {tweet_id}")
                logger.info(f"   é“¾æ¥: {tweet_url}")
                
                # æ ‡è®°ä¸ºå·²å‘å¸ƒ
                if self.mark_as_published(article):
                    logger.info("âœ… æ–‡ç« çŠ¶æ€æ›´æ–°æˆåŠŸ")
                else:
                    logger.warning("âš ï¸ æ–‡ç« çŠ¶æ€æ›´æ–°å¤±è´¥")
                
                return True
            else:
                logger.error(f"âŒ æ¨æ–‡å‘å¸ƒå¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"å‘å¸ƒæ–‡ç« æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False
    
    def mark_as_published(self, article: Dict) -> bool:
        """æ ‡è®°æ–‡ç« ä¸ºå·²å‘å¸ƒ"""
        try:
            source_file = article['_source_file']
            row_index = article['_row_index']
            
            # è¯»å–åŸå§‹æ–‡ä»¶
            with open(source_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                rows = list(reader)
                fieldnames = reader.fieldnames
            
            # æ‰¾åˆ°å‘å¸ƒçŠ¶æ€å­—æ®µ
            status_field = None
            for field in fieldnames:
                if 'æ˜¯å¦å‘å¸ƒ' in field:
                    status_field = field
                    break
            
            if not status_field:
                logger.error("æœªæ‰¾åˆ°å‘å¸ƒçŠ¶æ€å­—æ®µ")
                return False
            
            # æ›´æ–°çŠ¶æ€
            if row_index < len(rows):
                rows[row_index][status_field] = 'æ˜¯'
                
                # å†™å›æ–‡ä»¶
                with open(source_file, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(rows)
                
                # æ›´æ–°å†…å­˜ä¸­çš„æ•°æ®
                article['is_published'] = True
                article['published'] = 'æ˜¯'
                
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"æ ‡è®°å·²å‘å¸ƒæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        if not self.current_data:
            self.load_content_data()
        
        stats = {
            'total': len(self.current_data),
            'published': sum(1 for article in self.current_data if article['is_published']),
            'unpublished': 0,
            'by_account': {},
            'excluded_accounts': self.excluded_accounts
        }
        
        stats['unpublished'] = stats['total'] - stats['published']
        
        # æŒ‰è´¦å·ç»Ÿè®¡
        for article in self.current_data:
            account = article['publish_account'] or 'default'
            
            if account not in stats['by_account']:
                stats['by_account'][account] = {
                    'total': 0,
                    'published': 0,
                    'unpublished': 0,
                    'excluded': account in self.excluded_accounts
                }
            
            stats['by_account'][account]['total'] += 1
            if article['is_published']:
                stats['by_account'][account]['published'] += 1
            else:
                stats['by_account'][account]['unpublished'] += 1
        
        return stats
    
    def test_all_accounts(self) -> Dict:
        """æµ‹è¯•æ‰€æœ‰è´¦å·çš„è¿æ¥çŠ¶æ€"""
        return self.account_manager.test_all_accounts()
    
    def run_once(self) -> bool:
        """è¿è¡Œä¸€æ¬¡å‘å¸ƒä»»åŠ¡"""
        try:
            logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œå¤šè´¦å·å‘å¸ƒä»»åŠ¡")
            
            # æµ‹è¯•è´¦å·è¿æ¥
            account_results = self.test_all_accounts()
            logger.info("ğŸ“‹ è´¦å·è¿æ¥çŠ¶æ€:")
            for account_name, result in account_results.items():
                if result['status'] == 'success':
                    logger.info(f"   âœ… {account_name} (@{result['username']})")
                else:
                    logger.warning(f"   âŒ {account_name} - {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = self.get_statistics()
            logger.info(f"ğŸ“Š å†…å®¹ç»Ÿè®¡:")
            logger.info(f"   æ€»æ•°: {stats['total']}")
            logger.info(f"   å·²å‘å¸ƒ: {stats['published']}")
            logger.info(f"   æœªå‘å¸ƒ: {stats['unpublished']}")
            
            # æŒ‰è´¦å·æ˜¾ç¤ºç»Ÿè®¡
            for account, account_stats in stats['by_account'].items():
                if account_stats.get('excluded', False):
                    logger.info(f"   {account}: {account_stats['unpublished']} å¾…å‘å¸ƒ (å·²æš‚åœ)")
                else:
                    logger.info(f"   {account}: {account_stats['unpublished']} å¾…å‘å¸ƒ")
            
            # è·å–ä¸‹ä¸€ç¯‡æ–‡ç« 
            article = self.get_next_article()
            
            if not article:
                logger.info("âœ… æ²¡æœ‰å¾…å‘å¸ƒçš„æ–‡ç« ")
                return True
            
            logger.info(f"ğŸ“ å‡†å¤‡å‘å¸ƒ: {article['title']}")
            logger.info(f"ğŸ‘¤ ä½œè€…: {article['author']}")
            logger.info(f"ğŸ“ å‘å¸ƒè´¦å·: {article['publish_account']}")
            
            # å‘å¸ƒæ–‡ç« 
            success = self.publish_article(article)
            
            if success:
                logger.info("ğŸ‰ å¤šè´¦å·å‘å¸ƒä»»åŠ¡å®Œæˆ")
            else:
                logger.error("âŒ å¤šè´¦å·å‘å¸ƒä»»åŠ¡å¤±è´¥")
            
            return success
            
        except Exception as e:
            logger.error(f"è¿è¡Œå‘å¸ƒä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False
    
    def run_batch(self, max_posts: int = 5) -> Dict:
        """æ‰¹é‡è¿è¡Œå‘å¸ƒä»»åŠ¡"""
        try:
            logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å‘å¸ƒä»»åŠ¡ (æœ€å¤š {max_posts} ç¯‡)")
            
            results = {
                'success': 0,
                'failed': 0,
                'total': 0,
                'details': []
            }
            
            # æŒ‰è´¦å·åˆ†ç»„è·å–æ–‡ç« 
            articles_by_account = self.get_next_articles_by_account()
            
            if not articles_by_account:
                logger.info("âœ… æ²¡æœ‰å¾…å‘å¸ƒçš„æ–‡ç« ")
                return results
            
            # ä¸ºæ¯ä¸ªè´¦å·å‘å¸ƒä¸€ç¯‡æ–‡ç« 
            for account, articles in articles_by_account.items():
                if results['total'] >= max_posts:
                    break
                
                if not articles:
                    continue
                
                article = articles[0]  # å–ç¬¬ä¸€ç¯‡
                
                logger.info(f"ğŸ“ å‘å¸ƒåˆ°è´¦å· '{account}': {article['title']}")
                
                success = self.publish_article(article)
                
                result_detail = {
                    'account': account,
                    'title': article['title'],
                    'success': success
                }
                
                results['details'].append(result_detail)
                results['total'] += 1
                
                if success:
                    results['success'] += 1
                else:
                    results['failed'] += 1
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                time.sleep(2)
            
            logger.info(f"ğŸ‰ æ‰¹é‡å‘å¸ƒå®Œæˆ: {results['success']} æˆåŠŸ, {results['failed']} å¤±è´¥")
            
            return results
            
        except Exception as e:
            logger.error(f"æ‰¹é‡å‘å¸ƒæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return {'success': 0, 'failed': 0, 'total': 0, 'details': []}

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Twitterå¤šè´¦å·è‡ªåŠ¨å‘å¸ƒç³»ç»Ÿ")
    print("=" * 50)
    
    try:
        # æš‚æ—¶æ’é™¤contextspaceè´¦å·çš„è‡ªåŠ¨å‘å¸ƒ
        excluded_accounts = ['ContextSpace']
        
        # åˆ›å»ºå‘å¸ƒå™¨
        publisher = MultiAccountTwitterPublisher(excluded_accounts=excluded_accounts)
        
        # è¿è¡Œä¸€æ¬¡
        success = publisher.run_once()
        
        if success:
            print("âœ… å¤šè´¦å·å‘å¸ƒä»»åŠ¡å®Œæˆ")
        else:
            print("âŒ å¤šè´¦å·å‘å¸ƒä»»åŠ¡å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main() 